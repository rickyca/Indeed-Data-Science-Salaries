{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jobs2(URL):\n",
    "    '''\n",
    "    Scrapes an URL and returns the content of div tags with three different classes: \n",
    "    'row result', ' row result', and 'row sjlast result'\n",
    "    '''\n",
    "    response = requests.get(URL)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    j = []\n",
    "    jobs = soup.find_all('div', {'class': 'row result'}) \n",
    "    for job in jobs:\n",
    "        j.append(job)\n",
    "    jobs = soup.find_all('div', {'class': ' row result'}) \n",
    "    for job in jobs:\n",
    "        j.append(job)\n",
    "    jobs = soup.find_all('div', {'class': 'row sjlast result'}) \n",
    "    for job in jobs:\n",
    "        j.append(job)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_field(s, tag, class_=None, field_=None, text=True):\n",
    "    '''\n",
    "    Extracts a field that contains a tag. An attribute and its value can be used to narrow down\n",
    "    the output. It can return the text in the specified tag or a bs4 soup object from where \n",
    "    more filtering can be performed.\n",
    "    '''\n",
    "    try:\n",
    "        if field_ == None:\n",
    "            for d in s.find_all(tag):\n",
    "                return d.text\n",
    "        else:\n",
    "            for d in s.find_all(tag, {class_:field_}):\n",
    "                if text:\n",
    "                    return d.text.strip()\n",
    "                else:\n",
    "                    return d\n",
    "    except:\n",
    "        return\n",
    "\n",
    "def extract_location(s):\n",
    "    return extract_field(s, 'span', 'class','location')\n",
    "    \n",
    "def extract_company(s):\n",
    "    return extract_field(s, 'span', 'class','company')\n",
    "\n",
    "def extract_job(s):\n",
    "    return extract_field(s,'a')\n",
    "\n",
    "def extract_salary(s):\n",
    "    span = extract_field(s,'span', 'class', 'no-wrap')\n",
    "    if span == None:\n",
    "        span_aux = extract_field(s,'div', 'class', 'sjcl', text=False)\n",
    "        #print span_aux\n",
    "        span = extract_field(span_aux,'div', text=True)\n",
    "    if span:\n",
    "        return span.strip()\n",
    "    else:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parse_jobs(url):\n",
    "    '''\n",
    "    Combining previous functions, this ones does the GET request and gets all necessary fields.\n",
    "    It returns a dataframe.\n",
    "    '''\n",
    "    df = pd.DataFrame(columns=['location', 'company', 'title', 'salary'])\n",
    "    jobs = get_jobs2(url)\n",
    "    for job in jobs:\n",
    "        loc = extract_location(job)\n",
    "        comp = extract_company(job)\n",
    "        title = extract_job(job)\n",
    "        salary = extract_salary(job)\n",
    "        job_series = pd.Series([loc, comp, title, salary], index=['location', 'company', 'title', 'salary'])\n",
    "        df = df.append(job_series, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houston 2017-06-21 22:41:56.100185\n",
      "Phoenix 2017-06-21 22:49:03.561165\n",
      "Chicago 2017-06-21 22:56:21.847519\n",
      "San+Francisco 2017-06-21 23:03:42.040795\n",
      "New+York 2017-06-21 23:11:51.978023\n",
      "Dallas 2017-06-21 23:19:27.436621\n",
      "Philadelphia 2017-06-21 23:27:04.974835\n",
      "Denver 2017-06-21 23:34:37.023838\n",
      "Los+Angeles 2017-06-21 23:42:14.142316\n",
      "Pittsburgh 2017-06-21 23:49:22.286639\n",
      "Miami 2017-06-22 00:01:33.940304\n",
      "Atlanta 2017-06-22 00:09:50.531932\n",
      "Seattle 2017-06-22 00:17:03.601376\n",
      "Austin 2017-06-22 00:24:43.241152\n",
      "Portland 2017-06-22 00:31:44.263943\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 5000 \n",
    "\n",
    "# Init results\n",
    "results = []\n",
    "\n",
    "# Loop for cities and result pages\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami']):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_template\n",
    "        url = url.replace('{}',city,1)\n",
    "        url = url.replace('{}',str(start),1)\n",
    "        query = get_parse_jobs(url)\n",
    "        time.sleep(0.2)\n",
    "        results.append(query)\n",
    "    print city, datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Joins the results list (list of dataframes)\n",
    "r = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>MD Anderson Cancer Center</td>\n",
       "      <td>Institute Assoc Scientist III - Neurodegenerat...</td>\n",
       "      <td>$62,500 - $94,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Preferred Sands</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>Predictive Science</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>McKinsey &amp; Company</td>\n",
       "      <td>Analyst - Healthcare Analytics &amp; Delivery, McK...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston, TX 77046 (Montrose area)</td>\n",
       "      <td>Sunnova Energy Corporation</td>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Houston, TX 77073</td>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>Research and Development Scientist - Houston TX</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baytown, TX 77520</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Polymer Material Informatics Research Scientist</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Houston, TX 77032</td>\n",
       "      <td>Halliburton</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Houston, TX 77042 (West Houston area)</td>\n",
       "      <td>Tessella</td>\n",
       "      <td>Senior Oil &amp; Gas Analytics Consultant</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>MD Anderson Cancer Center</td>\n",
       "      <td>Computational Scientist</td>\n",
       "      <td>$76,400 - $114,600 a year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                location                     company  \\\n",
       "0                            Houston, TX   MD Anderson Cancer Center   \n",
       "1                            Houston, TX             Preferred Sands   \n",
       "2                          United States          Predictive Science   \n",
       "3                            Houston, TX          McKinsey & Company   \n",
       "4      Houston, TX 77046 (Montrose area)  Sunnova Energy Corporation   \n",
       "5                      Houston, TX 77073                Baker Hughes   \n",
       "6                      Baytown, TX 77520                  ExxonMobil   \n",
       "7                      Houston, TX 77032                 Halliburton   \n",
       "8  Houston, TX 77042 (West Houston area)                    Tessella   \n",
       "9                            Houston, TX   MD Anderson Cancer Center   \n",
       "\n",
       "                                               title  \\\n",
       "0  Institute Assoc Scientist III - Neurodegenerat...   \n",
       "1                                 Research Scientist   \n",
       "2                                     Data Scientist   \n",
       "3  Analyst - Healthcare Analytics & Delivery, McK...   \n",
       "4                               Quantitative Analyst   \n",
       "5    Research and Development Scientist - Houston TX   \n",
       "6    Polymer Material Informatics Research Scientist   \n",
       "7                                       Statistician   \n",
       "8              Senior Oil & Gas Analytics Consultant   \n",
       "9                            Computational Scientist   \n",
       "\n",
       "                      salary  \n",
       "0   $62,500 - $94,000 a year  \n",
       "1                       None  \n",
       "2                       None  \n",
       "3                       None  \n",
       "4                       None  \n",
       "5                       None  \n",
       "6                       None  \n",
       "7                       None  \n",
       "8                       None  \n",
       "9  $76,400 - $114,600 a year  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify\n",
    "r.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save to a .csv file\n",
    "r.to_csv(path_or_buf='ds_jobs.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using this code just to get the data\n",
    "# Cleaning is the following step"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
